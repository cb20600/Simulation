import os
from openai import OpenAI
from dotenv import load_dotenv

# # åˆå§‹åŒ– API
# load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# # æ¥æ”¶ç”¨æˆ·æŒ‡ä»¤
# user_input = input("Enter your robot instruction: ")

def parser(user_input):
    # LLM ç†è§£æŒ‡ä»¤å¹¶è¾“å‡ºä»»åŠ¡æ­¥éª¤ï¼ˆè‡ªç„¶è¯­è¨€æè¿°ï¼‰
    messages = [
        {
            "role": "system",
            "content": (
                "You are a robot assistant that understands natural language instructions.\n"
                "Your job is to interpret the user's task command and output a **step-by-step subtask plan**.\n"
                "Each step should be described clearly in natural language, including:\n"
                "- what to do\n"
                "- which objects are involved\n"
                "- what the goal is\n"
                "- any spatial relations or constraints\n\n"
                "Output should be plain text only, no JSON or code formatting.\n"
                "Example:\n"
                "1. Move the apple close to the banana.\n"
                "2. Rotate the apple to align with the banana.\n"
                "3. Place the potato between the banana and the orange."
            )
        },
        {
            "role": "user",
            "content": user_input
        }
    ]

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages,
        temperature=0.4
    )

    # æ‰“å°LLMè¾“å‡ºçš„ä»»åŠ¡è®¡åˆ’
    print("\nğŸ§  Subtask Plan:")
    print(response.choices[0].message.content)

    return response.choices[0].message.content

def trajectory_plan(subtask_txt_path="llm_subtasks.txt", grasp_json_path="grasp_infos.json"):
    """
    æ ¹æ® LLM å­ä»»åŠ¡æè¿°å’Œæ„ŸçŸ¥åˆ°çš„ç‰©ä½“æŠ“å–ä¿¡æ¯ï¼Œè°ƒç”¨ LLM ç”Ÿæˆä¸€ç³»åˆ—è½¨è¿¹ç‚¹åŠ¨ä½œè®¡åˆ’ã€‚

    å‚æ•°:
        subtask_txt_path (str): åŒ…å« LLM è¾“å‡ºå­ä»»åŠ¡æè¿°çš„ .txt æ–‡ä»¶è·¯å¾„
        grasp_json_path (str): åŒ…å«æ„ŸçŸ¥ä¿¡æ¯ï¼ˆä¸­å¿ƒç‚¹ã€è§’åº¦ã€å®½åº¦ï¼‰çš„ .json æ–‡ä»¶è·¯å¾„

    è¿”å›:
        trajectory_plan (str): LLM è¾“å‡ºçš„è‡ªç„¶è¯­è¨€è½¨è¿¹ç‚¹åŠ¨ä½œåºåˆ—
    """

    # è¯»å–å­ä»»åŠ¡æè¿°
    with open(subtask_txt_path, "r") as f:
        subtask_text = f.read()

    # è¯»å–æ„ŸçŸ¥åˆ°çš„ç‰©ä½“æŠ“å–ä¿¡æ¯
    with open(grasp_json_path, "r") as f:
        grasp_data = json.load(f)

    messages = [
        {
            "role": "system",
            "content": (
                "You are a robot trajectory planner. Based on the user's task breakdown and the sensed object information, "
                "generate a detailed motion plan for the robot arm to follow.\n"
                "Each action should include:\n"
                "- A step index\n"
                "- Target 3D position (x, y, z)\n"
                "- Target orientation (quaternion: x, y, z, w)\n"
                "- Gripper action: open or close (with value)\n"
                "- Description of what this step does\n\n"
                "Output in clear numbered steps in plain text.\n"
                "Avoid JSON or markdown formatting.\n"
                "The grasp_data contains: object index, center (u,v), grasp angle (degrees), width (meters). "
                "You may assume a mapping from (u,v) image center to (x,y,z) world coordinates is already done."
            )
        },
        {
            "role": "user",
            "content": f"Task description:\n{subtask_text.strip()}\n\nSensed grasp data:\n{json.dumps(grasp_data, indent=2)}"
        }
    ]

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages,
        temperature=0.4
    )

    result = response.choices[0].message.content
    print("ğŸ§  LLM Trajectory Plan:\n")
    print(result)

    return result
