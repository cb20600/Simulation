# from utils.pose_capture import simulate_and_capture_scene
from utils.yolo_utils import detect_fruits
from utils.sam2_utils import segment_with_sam2
from utils.coordinate import annotate_and_get_3d_coords
from utils.save_json import save_json_from_detection
from utils.rotate import extract_grasp_infos, grasp_angle_to_quaternion

if __name__ == "__main__": 
    '''
    1. è°ƒç”¨LLMè¯»å–ç”¨æˆ·æŒ‡ä»¤(éœ€è¦æ¨¡ç³ŠåŠŸèƒ½è¯†åˆ«æ‹¼å†™é”™è¯¯ç­‰): LLMè¾“å‡ºå­ä»»åŠ¡åºåˆ—
    2. åˆ›å»ºåœºæ™¯,æ‰§è¡Œåœºæ™¯å…¨è§ˆè¿åŠ¨,è°ƒç”¨æ‘„åƒå¤´æ‹æ‘„æ¡Œé¢å›¾åƒ: è¾“å‡ºä¸ºRGB-Då›¾åƒ
    3. ä½¿ç”¨yolo_utils.pyè¿›è¡Œè¯†åˆ«: image_rgb, boxes, yolo_centers, class_ids
    4. SAM2å¤„ç†(sam2_utils.py): out_masks, centers, save_path. è®¡ç®—ç‰©ä½“ä¸»è½´å‰¯è½´æ–¹å‘, ç»™å‡ºå¯¹åº”çš„quatå€¼(rotate.py)
    5. è°ƒç”¨corrdinate.pyåæŠ•å½±ç‚¹äº‘è®¡ç®—3Dä½ç½®, å¹¶ä½¿ç”¨save_json.pyä¿å­˜ä¸ºjsonæ–‡ä»¶
    6. LLMè¯»å–jsonæ–‡ä»¶å†…å®¹, å¹¶æ ¹æ®å­ä»»åŠ¡åºåˆ—ï¼Œç”Ÿæˆè¯¦ç»†çš„è½¨è¿¹ç‚¹å’Œä»»åŠ¡
    7. è°ƒç”¨ä»¿çœŸæ§åˆ¶å™¨æ‰§è¡Œè½¨è¿¹ç‚¹åºåˆ—, æ ¹æ®quatå€¼å’Œç‰©ä½“å®½åº¦è°ƒæ•´å¤¹çˆªè§’åº¦å’Œå¼€åˆå¤§å°
    '''
    img_path = "imgs/sim_fruit_from_camera.png"
    yolo_path = "checkpoints/best.pt"
    sam_model_path = "checkpoints/sam2_b.pt"
    npz_path = "imgs/sim_fruit_from_camera.npz"

    # ======================= Step 2: Capture Pose =======================
    simulate_and_capture_scene()

    # ======================= Step 3: YOLO Detection =======================
    image_rgb, boxes, yolo_centers, class_ids, yolo_output_path = detect_fruits(
        input_path=img_path,
        yolo_path=yolo_path
    )

    if len(boxes) == 0:
        print("âŒ No objects detected by YOLO. Exit!")
        exit()

    # ======================= Step 4: SAM2 Segmentation ====================
    masks, sam_centers = segment_with_sam2(
        image_rgb=image_rgb,
        boxes=boxes,
        sam_model_path=sam_model_path,
        input_image_path=img_path
    )

    # Optional: extract grasp angles and quaternions
    grasp_infos, grasp_img_path = extract_grasp_infos(
        image_rgb=image_rgb,
        masks=masks,
        pixel_to_meter=0.0025,
        output_path=img_path.replace(".png", "_grasp_infos.png")
    )

    quaternions = []
    for info in grasp_infos:
        angle_deg = info["angle_deg"]
        quat = grasp_angle_to_quaternion(angle_deg)
        quaternions.append(quat)
        print(f"ğŸ” Object #{info['index']} grasp angle = {angle_deg:.2f}Â°, quaternion = {quat}")

    # ======================= Step 5: 3D Coordinate Projection =============
    coords_3d = annotate_and_get_3d_coords(
        image_path=img_path,
        npz_path=npz_path,
        pixel_points=sam_centers  # Prefer sam_centers for precision
    )

    # Print coordinates
    for i, coord in enumerate(coords_3d):
        if coord is not None:
            print(f"ğŸ§­ Object #{i} 3D position: [{coord[0]:.3f}, {coord[1]:.3f}, {coord[2]:.3f}]")
        else:
            print(f"âš ï¸ Object #{i} has no valid 3D coordinate")

    from utils.save_json import save_json_from_detection

    save_json_from_detection(
        yolo_path=yolo_path,
        class_ids=class_ids,
        centers=sam_centers,
        coords_3d=coords_3d,
        widths=[info["width_m"] for info in grasp_infos],
        quaternions=quaternions,
        # gripper_opens=[compute_gripper_open_close(info["width_m"])[0] for info in grasp_infos],
        # gripper_closes=[compute_gripper_open_close(info["width_m"])[1] for info in grasp_infos],
        # output_path=json_path
    )
